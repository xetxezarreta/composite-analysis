{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from glob import glob\n",
    "import pandas as pd\n",
    "import csv\n",
    "from tsfresh import extract_features\n",
    "from tsfresh.utilities.distribution import MultiprocessingDistributor\n",
    "\n",
    "files = glob('data/*.csv')\n",
    "totals = ['Total_PorosityQuantity', 'Total_PorosityQuality', 'Total_UnfilledZones', 'Total_FillingQuality', 'TOTAL_QUALITY']\n",
    "\n",
    "df_list = list()\n",
    "target = list()\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    df = pd.read_csv(file)\n",
    "\n",
    "    if df.iloc[:,-1].unique()[0] == target_value:\n",
    "        df['id'] = i\n",
    "        target.append(df.TOTAL_QUALITY.unique()[0])\n",
    "        df = df.drop(axis=1, columns=totals)   \n",
    "\n",
    "        consta = [col for col in df if col.endswith(('K1', 'K2', 'K3'))]\n",
    "        series = [col for col in df if col.endswith(('Time', 'id', 'Flow rate', 'Pressure'))]  \n",
    "\n",
    "        distributor = MultiprocessingDistributor(n_workers=8, disable_progressbar=True, progressbar_title=\"Feature Extraction\")\n",
    "        extracted_features = extract_features(df[series], column_id='id', column_sort='Time', distributor=distributor)\n",
    "\n",
    "        for j in consta:\n",
    "            extracted_features[j] = df[j].unique()[0] \n",
    "\n",
    "        df_list.append(extracted_features)   \n",
    "\n",
    "\n",
    "\n",
    "df = pd.concat(df_list)\n",
    "df.head()        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TS-Featurizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU count: 8\n",
      "Extracting file: 0 (D:\\master\\LIP\\composite-analysis\\data\\0.csv)\n",
      "\n",
      "\n",
      "-------------------------------------------------- Modeling started --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:19<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file: 1 (D:\\master\\LIP\\composite-analysis\\data\\1.csv)\n",
      "\n",
      "\n",
      "-------------------------------------------------- Modeling started --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:23<00:00,  1.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file: 2 (D:\\master\\LIP\\composite-analysis\\data\\10.csv)\n",
      "\n",
      "\n",
      "-------------------------------------------------- Modeling started --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:20<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file: 3 (D:\\master\\LIP\\composite-analysis\\data\\100.csv)\n",
      "\n",
      "\n",
      "-------------------------------------------------- Modeling started --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file: 4 (D:\\master\\LIP\\composite-analysis\\data\\1000.csv)\n",
      "\n",
      "\n",
      "-------------------------------------------------- Modeling started --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:22<00:00,  1.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file: 5 (D:\\master\\LIP\\composite-analysis\\data\\10000.csv)\n",
      "\n",
      "\n",
      "-------------------------------------------------- Modeling started --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:20<00:00,  1.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file: 6 (D:\\master\\LIP\\composite-analysis\\data\\10001.csv)\n",
      "\n",
      "\n",
      "-------------------------------------------------- Modeling started --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:20<00:00,  1.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file: 7 (D:\\master\\LIP\\composite-analysis\\data\\10002.csv)\n",
      "\n",
      "\n",
      "-------------------------------------------------- Modeling started --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 30/30 [00:23<00:00,  1.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting file: 8 (D:\\master\\LIP\\composite-analysis\\data\\10003.csv)\n",
      "\n",
      "\n",
      "-------------------------------------------------- Modeling started --------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\r",
      "  0%|                                                                                                                                        | 0/30 [00:00<?, ?it/s]"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from glob import glob\n",
    "import multiprocessing\n",
    "from ts_featurizer.base import TimeSeriesFeaturizer\n",
    "\n",
    "files = glob('D:\\master\\LIP\\composite-analysis\\data\\*.csv')\n",
    "totals = ['Total_PorosityQuantity', 'Total_PorosityQuality', 'Total_UnfilledZones', 'Total_FillingQuality', 'TOTAL_QUALITY']\n",
    "\n",
    "jobs = multiprocessing.cpu_count()\n",
    "print(\"CPU count: \"+ str(jobs))\n",
    "\n",
    "output_file = 'D:/master/LIP/composite-analysis/tmp/extracted_data_ts_featurizer.csv'\n",
    "\n",
    "for i, file in enumerate(files):\n",
    "    if not file.endswith('.csv'):\n",
    "        continue\n",
    "\n",
    "    print(\"Extracting file: \" + str(i) + \" (\" + file + \")\")\n",
    "    df = pd.read_csv(file)\n",
    "    df['id'] = i\n",
    "    target = df.TOTAL_QUALITY.unique()[0]\n",
    "    df = df.drop(axis=1, columns=totals)\n",
    "\n",
    "    consta = [col for col in df if col.endswith(('K1', 'K2', 'K3'))]\n",
    "    series = [col for col in df if col.endswith(('Time', 'id', 'Flow rate', 'Pressure'))]\n",
    "    \n",
    "    \n",
    "    tseries = TimeSeriesFeaturizer()\n",
    "    extracted_features = tseries.featurize(df[series], n_jobs=jobs)\n",
    "    \n",
    "    #extracted_features = extract_features(df[series], disable_progressbar=True, column_id='id', column_sort='Time', n_jobs=jobs)\n",
    "\n",
    "    #for j in consta:\n",
    "    #    extracted_features[j] = df[j].unique()[0]    \n",
    "        \n",
    "    extracted_features['target'] = target    \n",
    "        \n",
    "    if not os.path.isfile(output_file):\n",
    "        extracted_features.to_csv(output_file)\n",
    "    else:\n",
    "        extracted_features.to_csv(output_file, mode='a', header=False)\n",
    "\n",
    "print('Tsfresh succesfully finished')\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
